{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPB8dX8ArgLS8eG8NqMzwSG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"nVCXHbd-7wqr"}},{"cell_type":"code","source":["import os\n","import cv2\n","import random\n","import glob\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"],"metadata":{"id":"aqEsTVgh7yA-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Util Code"],"metadata":{"id":"bzQVZGN8pwNq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hUjLk75IekpL"},"outputs":[],"source":["def count_images_per_class(data_path):\n","    class_counts = {}\n","    for tumor_type in os.listdir(data_path):\n","        class_dir = os.path.join(data_path, tumor_type)\n","        if os.path.isdir(class_dir):\n","            num_images = len(glob.glob(f\"{class_dir}/*.jpg\"))\n","            class_counts[tumor_type] = num_images\n","            print(f\"{tumor_type}: {num_images} images\")\n","    return class_counts\n","\n","def plot_random_images_per_class(data_path, num_samples=1, figsize=(12, 8)):\n","    classes = os.listdir(data_path)\n","    plt.figure(figsize=figsize)\n","\n","    for i, tumor_type in enumerate(classes):\n","        tumor_dir = os.path.join(data_path, tumor_type)\n","        image_files = os.listdir(tumor_dir)\n","        if not image_files:\n","            continue\n","        random_image = random.choice(image_files)\n","        image_path = os.path.join(tumor_dir, random_image)\n","        img = cv2.imread(image_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","        plt.subplot(2, 2, i+1)\n","        plt.imshow(img)\n","        plt.title(tumor_type)\n","        plt.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","def create_generators(train_dir,\n","                      test_dir,\n","                      img_size=(224, 224),\n","                      batch_size=32,\n","                      preprocessing=None,\n","                      val_split=0.2,\n","                      shuffle_test=False):\n","    \"\"\"\n","    Creates train, validation, and test data generators.\n","\n","    Args:\n","        train_dir (str): Path to training directory.\n","        test_dir (str): Path to testing directory.\n","        img_size (tuple): Desired image size (height, width).\n","        batch_size (int): Number of images per batch.\n","        preprocessing (function): Optional preprocessing function (e.g., preprocess_input).\n","        val_split (float): Fraction of training data to use for validation.\n","        shuffle_test (bool): If False, test generator won't shuffle files (important for eval consistency).\n","\n","    Returns:\n","        train_gen, val_gen, test_gen: Keras ImageDataGenerator iterators\n","    \"\"\"\n","    if preprocessing:\n","        train_val_datagen = ImageDataGenerator(\n","            preprocessing_function=preprocessing,\n","            validation_split=val_split\n","        )\n","        test_datagen = ImageDataGenerator(preprocessing_function=preprocessing)\n","    else:\n","        train_val_datagen = ImageDataGenerator(rescale=1./255, validation_split=val_split)\n","        test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","    train_gen = train_val_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=img_size,\n","        batch_size=batch_size,\n","        class_mode='sparse',\n","        subset='training'\n","    )\n","\n","    val_gen = train_val_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=img_size,\n","        batch_size=batch_size,\n","        class_mode='sparse',\n","        subset='validation'\n","    )\n","\n","    test_gen = test_datagen.flow_from_directory(\n","        test_dir,\n","        target_size=img_size,\n","        batch_size=batch_size,\n","        class_mode='sparse',\n","        shuffle=shuffle_test\n","    )\n","\n","    return train_gen, val_gen, test_gen"]},{"cell_type":"code","source":["import os\n","from tensorflow.keras.models import load_model\n","\n","def save_model_to_drive(model, model_name='model', drive_path='/content/drive/MyDrive/BrainTumorClassification/saved_models'):\n","\n","    \"\"\"\n","    Saves a Keras model to Google Drive in `.keras` format.\n","\n","    Args:\n","        model: Trained Keras model.\n","        model_name (str): Name to save the file as.\n","        drive_path (str): Destination folder path in Google Drive.\n","    \"\"\"\n","    os.makedirs(drive_path, exist_ok=True)\n","    filepath = os.path.join(drive_path, f\"{model_name}.keras\")\n","    model.save(filepath)\n","    print(f\"âœ… Model saved to Drive at: {filepath}\")\n","\n","\n","def load_model_from_drive(model_name='model', drive_path='/content/drive/MyDrive/saved_models'):\n","    \"\"\"\n","    Loads a `.keras` model from Google Drive.\n","\n","    Args:\n","        model_name (str): Name of the file to load (without extension).\n","        drive_path (str): Folder path in Google Drive.\n","\n","    Returns:\n","        Loaded Keras model\n","    \"\"\"\n","    filepath = os.path.join(drive_path, f\"{model_name}.keras\")\n","    if not os.path.exists(filepath):\n","        raise FileNotFoundError(f\"No model found at {filepath}\")\n","    print(f\"ðŸ“¦ Loading model from: {filepath}\")\n","    return load_model(filepath)\n"],"metadata":{"id":"__TXw_ZJlrkJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_augmented_train_generator(train_dir, img_size=(224, 224), batch_size=32):\n","    train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        rotation_range=15,\n","        width_shift_range=0.1,\n","        height_shift_range=0.1,\n","        brightness_range=(0.8, 1.2),\n","        zoom_range=0.2,\n","        shear_range=0.1,\n","        horizontal_flip=True,\n","        fill_mode='nearest'\n","    )\n","\n","    train_gen = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=img_size,\n","        batch_size=batch_size,\n","        class_mode='sparse',\n","        shuffle=True\n","    )\n","\n","    return train_gen\n"],"metadata":{"id":"seXqqxgm759I"},"execution_count":null,"outputs":[]}]}